{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "happy-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import iqr\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "from underthesea import word_tokenize, pos_tag, sent_tokenize\n",
    "import regex\n",
    "import demoji\n",
    "from pyvi import ViPosTagger, ViTokenizer\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# for report:\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "# vẽ đường cong ROC\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "attempted-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_excel('Data/Online Retail.xlsx', sheet_name = 'Online Retail', engine='openpyxl')\n",
    "# df = pd.read_csv('Data/poverty.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5db8fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hàm kiểm tra và tính số lượng, tỷ trọng outliers\n",
    "def check_outlier(col):\n",
    "    Q1 = np.percentile(col, 25)\n",
    "    print('Q1:       ', Q1)\n",
    "    Q3 = np.percentile(col, 75)\n",
    "    print('Q3:       ', Q3)\n",
    "    IQR = scipy.stats.iqr(col)\n",
    "    print('IQR:      ', IQR)\n",
    "    highOutliers = (col >= Q3 + 1.5*IQR).sum()\n",
    "    lowOutliers  = (col <= Q1 - 1.5*IQR).sum()\n",
    "    print('# Number of upper outliers: ', highOutliers)\n",
    "    print('# Number of lower outliers: ', lowOutliers)\n",
    "    print('# Percentage of ouliers:    ', (highOutliers + lowOutliers)/col.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f793dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hàm remove outliers\n",
    "def remove_outlier(variable, data_param):\n",
    "# Detection\n",
    "    Q1 = np.percentile(data_param[variable], 25)\n",
    "    Q3 = np.percentile(data_param[variable], 75)\n",
    "    IQR = scipy.stats.iqr(data_param[variable])    \n",
    "    # Upper bound\n",
    "    upper = np.where(data_param[variable] >= (Q3 + 1.5*IQR))\n",
    "    # Lower bound\n",
    "    lower = np.where(data_param[variable] <= (Q1 - 1.5*IQR))\n",
    "    # Removing the Outliers\n",
    "    data_param.drop(upper[0], inplace = True)\n",
    "    data_param.drop(lower[0], inplace = True)\n",
    "    data_param.reset_index(drop=True, inplace=True)\n",
    "    return data_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9691bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text, emoji_dict, teen_dict, wrong_lst):\n",
    "    document = text.lower()\n",
    "    document = document.replace(\"’\",'')\n",
    "    document = regex.sub(r'\\.+', \".\", document)\n",
    "    \n",
    "#     # Remove punctuation\n",
    "#     document = regex.sub('[^\\w\\s]', ' ', document)\n",
    "#     punctuation = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "#     for char in punctuation:\n",
    "#         document = document.replace(char, ' ')\n",
    "\n",
    "#     # Remove numbers, only keep letters\n",
    "#     document = regex.sub('[\\w]*\\d+[\\w]*', '', document)\n",
    "\n",
    "#     # Some lines start with a space, remove them\n",
    "#     document = regex.sub('^[\\s]{1,}', '', document)    \n",
    "    \n",
    "#     # Remove multiple spaces with one space\n",
    "#     document = regex.sub('[\\s]{2,}', ' ', document)\n",
    "\n",
    "#     # Some lines end with a space, remove them\n",
    "#     document = regex.sub('[\\s]{1,}$', '', document)    \n",
    "\n",
    "#     # Remove end of line characters\n",
    "#     document = regex.sub(r'[\\r\\n]+', ' ', document)    \n",
    "\n",
    "#     # Remove HTTP links\n",
    "#     document = regex.sub(r'((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*', '',\n",
    "#                                           document)    \n",
    "    new_sentence =''\n",
    "    for sentence in sent_tokenize(document):\n",
    "        # if not(sentence.isascii()):\n",
    "        ###### CONVERT EMOJICON\n",
    "        sentence = ''.join(emoji_dict[word]+' ' if word in emoji_dict else word for word in list(sentence))\n",
    "        ###### CONVERT TEENCODE\n",
    "        sentence = ' '.join(teen_dict[word] if word in teen_dict else word for word in sentence.split())\n",
    "        ###### DEL Punctuation & Numbers\n",
    "        pattern = r'(?i)\\b[a-záàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ]+\\b'\n",
    "        sentence = ' '.join(regex.findall(pattern,sentence))\n",
    "        ###### DEL wrong words   \n",
    "        sentence = ' '.join('' if word in wrong_lst else word for word in sentence.split())\n",
    "        new_sentence = new_sentence+ sentence + '. '                    \n",
    "    document = new_sentence  \n",
    "    #print(document)\n",
    "    ###### DEL excess blank space\n",
    "    document = regex.sub(r'\\s+', ' ', document).strip()\n",
    "    #...\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5db966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuẩn hóa unicode tiếng việt\n",
    "def loaddicchar():\n",
    "    uniChars = \"àáảãạâầấẩẫậăằắẳẵặèéẻẽẹêềếểễệđìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵÀÁẢÃẠÂẦẤẨẪẬĂẰẮẲẴẶÈÉẺẼẸÊỀẾỂỄỆĐÌÍỈĨỊÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢÙÚỦŨỤƯỪỨỬỮỰỲÝỶỸỴÂĂĐÔƠƯ\"\n",
    "    unsignChars = \"aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU\"\n",
    "\n",
    "    dic = {}\n",
    "    char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split(\n",
    "        '|')\n",
    "    charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split(\n",
    "        '|')\n",
    "    for i in range(len(char1252)):\n",
    "        dic[char1252[i]] = charutf8[i]\n",
    "    return dic\n",
    " \n",
    "# Đưa toàn bộ dữ liệu qua hàm này để chuẩn hóa lại\n",
    "def covert_unicode(txt):\n",
    "    dicchar = loaddicchar()\n",
    "    return regex.sub(\n",
    "        r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n",
    "        lambda x: dicchar[x.group()], txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b025e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_special_word(text):\n",
    "    new_text = ''\n",
    "    text_lst = text.split()\n",
    "    i= 0\n",
    "    if 'không' in text_lst:\n",
    "        while i <= len(text_lst) - 1:\n",
    "            word = text_lst[i]\n",
    "            #print(word)\n",
    "            #print(i)\n",
    "            if  word == 'không':\n",
    "                next_idx = i+1\n",
    "                if next_idx <= len(text_lst) -1:\n",
    "                    word = word +'_'+ text_lst[next_idx]\n",
    "                i= next_idx + 1\n",
    "            else:\n",
    "                i = i+1\n",
    "            new_text = new_text + word + ' '\n",
    "    else:\n",
    "        new_text = text\n",
    "    return new_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c69224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_postag_thesea(text):\n",
    "    new_document = ''\n",
    "    for sentence in sent_tokenize(text):\n",
    "        sentence = sentence.replace('.','')\n",
    "        ###### POS tag\n",
    "        lst_word_type = ['N','Np','A','AB','V','VB','VY','R']\n",
    "        # lst_word_type = ['A','AB','V','VB','VY','R']\n",
    "        sentence = ' '.join( word[0] if word[1].upper() in lst_word_type else '' for word in pos_tag(process_special_word(word_tokenize(sentence, format=\"text\"))))\n",
    "        new_document = new_document + sentence + ' '\n",
    "    ###### DEL excess blank space\n",
    "    new_document = regex.sub(r'\\s+', ' ', new_document).strip()\n",
    "    return new_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a484f9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(text, stopwords):\n",
    "    ###### REMOVE stop words\n",
    "    document = ' '.join('' if word in stopwords else word for word in text.split())\n",
    "    #print(document)\n",
    "    ###### DEL excess blank space\n",
    "    document = regex.sub(r'\\s+', ' ', document).strip()\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acceptable-return",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze one continuous variable\n",
    "def oneContAnalysis(col):\n",
    "    print('\\n===================== Các chỉ số thống kê =========================')\n",
    "    print('\\nStats:    ', col.describe(include='all'))\n",
    "    print('\\nMedian:   ', col.median())\n",
    "    print('Mode:     ', col.mode())\n",
    "    print('Range:    ', np.ptp(col))\n",
    "    Q1 = np.percentile(col, 25)\n",
    "    Q3 = np.percentile(col, 75)\n",
    "    print('Q1 = ', Q1)\n",
    "    print('Q3 = ', Q3)\n",
    "    iqr = scipy.stats.iqr(col)\n",
    "    print('IQR:      ', iqr)\n",
    "    print('Variance: ', col.var())\n",
    "    print('Std:      ', col.std())\n",
    "    \n",
    "    skew = round(col.skew(), 2)\n",
    "    print('Skewness: ', skew)\n",
    "    if (skew > 0):\n",
    "        print('\\t\\tPhân phối lệch phải')\n",
    "    else: \n",
    "        print('\\t\\tPhân phối lệch trái')\n",
    "    kur = round(col.kurtosis(), 2)\n",
    "    print('Kurtosis: ', kur)\n",
    "    if (kur > 0):\n",
    "        print('\\t\\t phân phối nhọn hơn phân phối chuẩn')\n",
    "    else: \n",
    "        print('\\t\\t phân phối ít nhọn hơn phân phối chuẩn')\n",
    "    \n",
    "    print('\\n======= Visualization========\\n### Histogram')\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.distplot(col)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(col)\n",
    "    plt.show()\n",
    "    print('### Boxplot')\n",
    "    plt.figure(figsize=(4,8))\n",
    "    plt.boxplot(col)\n",
    "    plt.show()\n",
    "    \n",
    "    highOutliers = (col > Q3 + 1.5*iqr).sum()\n",
    "    lowOutliers = (col < Q1 - 1.5*iqr).sum()\n",
    "    print('# Number of upper outliers: ', highOutliers)\n",
    "    print('# Number of lower outliers: ', lowOutliers)\n",
    "    print('# Percentage of ouliers:    ', (highOutliers + lowOutliers)/col.shape[0])\n",
    "\n",
    "    \n",
    "# Function to analyze one categorical variable\n",
    "def oneCategoryAnalysis(col):\n",
    "    count = col.groupby(col).size()\n",
    "    print(count)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    count.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "effective-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze relationship between categorical-continuous variables.\n",
    "def contCatAnalysis (cat, cont):\n",
    "    data = pd.DataFrame([cat, cont]).T\n",
    "    \n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.boxplot(x=cat, y = cont, palette=\"Set3\") \n",
    "    plt.show()\n",
    "    \n",
    "    model = ols('cont ~ C(cat)', data=data).fit()\n",
    "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "    print(anova_table)\n",
    "    \n",
    "    # perform multiple pairwise comparison (Tukey HSD)\n",
    "    m_comp = pairwise_tukeyhsd(endog=cont, \n",
    "    groups=cat, \n",
    "    alpha=0.05)\n",
    "    print('\\n', m_comp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "boolean-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze relationship between two categorical variables.\n",
    "\n",
    "def catCatAnalysis(cat1, cat2):                      # takes 2 columns\n",
    "    # Contingency table: Ho: 2 bien independent\n",
    "    table_FB = pd.crosstab(cat1, cat2)\n",
    "    print(table_FB)\n",
    "    \n",
    "    plt.figure(figsize=(12,10))\n",
    "    table_FB.plot(kind='bar', stacked=True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Chi-Square Test\n",
    "    stat, p, dof, expected = chi2_contingency(table_FB)\n",
    "    print('dof=%d' % dof)\n",
    "    print('p=', p)\n",
    "    \n",
    "    # interpret test-statistic\n",
    "    prob = 0.95\n",
    "    critical = chi2.ppf(prob, dof)\n",
    "    print('probability=%.3f, critical=%.3f, stat=%.3f' % (prob, critical, stat))\n",
    "    \n",
    "    # interpret p-value\n",
    "    alpha = 1.0 - prob\n",
    "    print('significance=%.3f, p=%.3f' % (alpha, p))\n",
    "    if p <= alpha:\n",
    "        print('Dependent (reject H0)')\n",
    "    else:\n",
    "        print('Independent (fail to reject H0)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "listed-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Function phân tích mối quan hệ continuous-continuous\n",
    "\n",
    "def contContAnalysis(v1, v2):                        # names of 2 columns, df global                   \n",
    "    print('\\n#', v1, 'VS', v2, '\\n')    \n",
    "    print(df[[v1, v2]].corr())    \n",
    "    sns.pairplot(df[[v1, v2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "gross-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply SelectKBest class to extract all best features\n",
    "\n",
    "# bestfeatures = SelectKBest(score_func=f_regression, k=2)\n",
    "# fit = bestfeatures.fit(X,y)\n",
    "# dfscores = pd.DataFrame(fit.scores_)\n",
    "# dfcolumns = pd.DataFrame(X.columns)\n",
    "# # Concat two dataframes for better visualization \n",
    "# featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "# featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "# # Sorting in descending order \n",
    "# featureScores.sort_values(\"Score\", ascending = False, inplace = True)\n",
    "# print(featureScores)  \n",
    "\n",
    "# # Correlation Matrix with Heatmap\n",
    "# corrmat = df.corr()\n",
    "# top_corr_features = corrmat.index\n",
    "# print(corrmat)\n",
    "\n",
    "# plt.figure(figsize=(15,7))\n",
    "# # plot heat map\n",
    "# g=sns.heatmap(df[top_corr_features].corr(),cmap=\"RdYlGn\", annot=True) \n",
    "# # annot=True: nếu muốn in cả giá trị\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "parental-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## dummies, scaler, polynomials......\n",
    "\n",
    "# X = pd.get_dummies(data = X, drop_first = True)\n",
    "# y = df['loan_status'].apply(lambda x: 0 if (x == 'PAIDOFF') else 1)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# X[['Principal','terms','age']] = scaler.fit_transform(X[['Principal','terms','age']])\n",
    "\n",
    "# pf = PolynomialFeatures(degree=2)\n",
    "# X = pf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "narrow-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearModel(X, y):    # X DataFrame, y series\n",
    "   \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    yhat_train = model.predict(X_train)\n",
    "    yhat_test = model.predict(X_test)\n",
    "    \n",
    "    # tính R^2\n",
    "    print('The train R-squared:', model.score(X_train, y_train))\n",
    "    print('The test R-squared:', model.score(X_test, y_test))\n",
    "    \n",
    "    mse_train = mean_squared_error(y_true=y_train, y_pred=yhat_train)\n",
    "    mse_test = mean_squared_error(y_true=y_test, y_pred=yhat_test)\n",
    "    mae_train = mean_absolute_error(y_true=y_train, y_pred=yhat_train)\n",
    "    mae_test = mean_absolute_error(y_true=y_test, y_pred=yhat_test)\n",
    "\n",
    "    print('\\nThe MSE of y and predicted in train:', mse_train)\n",
    "    print('The MSE of y and predicted in test:', mse_test)\n",
    "    print('The MAE of y and predicted in train:', mae_train)\n",
    "    print('The MAE of y and predicted in test:', mae_test)\n",
    "    \n",
    "    print('\\nSlope: ', model.coef_)\n",
    "    print('Intercept: ', model.intercept_)\n",
    "    \n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.scatter(yhat_test, y_test)\n",
    "    plt.xlabel('Model Predictions - y_predict')\n",
    "    plt.ylabel('True values - y_test')\n",
    "    plt.plot([np.min(y),np.max(y) ], [np.min(y),np.max(y) ], color='r')\n",
    "    plt.show()\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(16, 8))\n",
    "    # train\n",
    "    sns.kdeplot(y_train, color='r', ax=ax1)\n",
    "    sns.kdeplot(yhat_train, color='b', ax=ax1)\n",
    "    ax1.set_title('Actual vs Predicted in Train values')\n",
    "\n",
    "    # test\n",
    "    sns.kdeplot(y_test, color='r', label='Actual Values', ax=ax2)\n",
    "    sns.kdeplot(yhat_test, color='b', label='Predicted Values', ax=ax2)\n",
    "    ax2.set_title('Actual vs Predicted in Test values')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "religious-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model_reg(y,y_pred):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(121)\n",
    "    plt.scatter(y_pred,y)\n",
    "    plt.xlabel('Model Predictions')\n",
    "    plt.ylabel('True Value')\n",
    "    plt.plot([0,np.max(y)+2*np.min(y)],[0,np.max(y)+2*np.min(y)],'-',color='r')\n",
    "    plt.subplot(122)\n",
    "    sns.distplot(y, hist=False,color='r',label='True Value')\n",
    "    sns.distplot(y_pred, hist=False,color='b',label='Model Predictions',axlabel='Distribution')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "civic-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_score_model_reg(y,y_pred):\n",
    "    r2 = r2_score(y,y_pred)\n",
    "    mse = mean_squared_error(y,y_pred)\n",
    "    msa = mean_absolute_error(y,y_pred)\n",
    "    return r2, mse, msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fifty-bracelet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_model_reg(df['Actual Value'],df['Predict Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "solar-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2, mse, mae = static_score_model_reg(df['Actual Value'],df['Predict Value'])\n",
    "# print('Model score:',r2)\n",
    "# print('Model MSE:',mse)\n",
    "# print('Model MSA:',mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "colonial-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slope = model.coef_\n",
    "# slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adult-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intercept = model.intercept_\n",
    "# intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "artistic-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x test data....list\n",
    "# y_predict = model.predict(np.array(x).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "positive-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "faced-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticModel(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "    \n",
    "    model = LogisticRegression(solver = 'lbfgs', multi_class='multinomial')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    yhat_train = model.predict(X_train)\n",
    "    yhat_test = model.predict(X_test)\n",
    "    \n",
    "    yhat_train_proba = model.predict_proba(X_train)\n",
    "    yhat_test_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    print('\\nTrain:', accuracy_score(y_train, yhat_train))\n",
    "    print('Test:', accuracy_score(y_test, yhat_test))\n",
    "    \n",
    "    # tính R^2\n",
    "    print('\\nThe train R-squared (accuracy_score):', model.score(X_train, y_train))\n",
    "    print('The test R-squared (accuracy_score):', model.score(X_test, y_test))\n",
    "        \n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_true=y_test, y_pred=yhat_test)\n",
    "    print('\\nConfusion Matrix:\\n', cm)\n",
    "    \n",
    "    \n",
    "    # target_names = [....how many classification..]\n",
    "    print(classification_report(y_true=y_test, y_pred=yhat_test))  # target_names = target_names\n",
    "    \n",
    "    roc_auc_score(y_true=y_test, y_score=yhat_test_proba[:, 1])\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_true=y_test, y_score=yhat_test_proba[:,1])\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot([0,1], [0,1], 'r--')\n",
    "    plt.plot(fpr, tpr, marker='.')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.show()\n",
    "    \n",
    "    cm_df = pd.DataFrame(cm) # index = target_names, columns = target_names\n",
    "    plt.figure(figsize = (8,6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='g', cmap='Blues')\n",
    "    plt.title('Logistic Regression\\nAccuracy: {0:.3f}'.format(accuracy_score(y_test, yhat_test)))\n",
    "    plt.ylabel('True Values')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.show()\n",
    "    \n",
    "    return model         #scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "pleasant-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticModelMulti_y(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    \n",
    "    model = LogisticRegression(solver = 'lbfgs', multi_class='multinomial')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    yhat_train = model.predict(X_train)\n",
    "    yhat_test = model.predict(X_test)\n",
    "    \n",
    "#     yhat_train_proba = model.predict_proba(X_train)\n",
    "#     yhat_test_proba = model.predict_proba(X_test)\n",
    "    \n",
    "#     print('\\nTrain:', accuracy_score(y_train, yhat_train))\n",
    "#     print('Test:', accuracy_score(y_test, yhat_test))\n",
    "    \n",
    "    # tính R^2\n",
    "    print('\\nThe train R-squared (accuracy_score):', model.score(X_train, y_train))\n",
    "    print('The test R-squared (accuracy_score):', model.score(X_test, y_test))\n",
    "        \n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_true=y_test, y_pred=yhat_test)\n",
    "    print('\\nConfusion Matrix:\\n', cm)\n",
    "        \n",
    "    # target_names = [....how many classification..]\n",
    "    print(classification_report(y_true=y_test, y_pred=yhat_test))  # target_names = target_names\n",
    "    \n",
    "    cm_df = pd.DataFrame(cm) # index = target_names, columns = target_names\n",
    "    plt.figure(figsize = (8,6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='g', cmap='Blues')\n",
    "    plt.title('Logistic Regression\\nAccuracy: {0:.3f}'.format(accuracy_score(y_test, yhat_test)))\n",
    "    plt.ylabel('True Values')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.show()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hawaiian-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def Static_score_model_class(y, y_pred, aver=None):\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred, average = aver)\n",
    "    recall = recall_score(y, y_pred, average = aver)\n",
    "    f1 = f1_score(y, y_pred, average = aver)\n",
    "    \n",
    "    return accuracy, recall, precision, f1\n",
    "\n",
    "# print('Accuracy: ', Res[0])\n",
    "# print('Recall: ', Res[1])\n",
    "# print('Precision: ', Res[2])\n",
    "# print('f1-Score: ', Res[3])\n",
    "\n",
    "# # target_names = [....how many classification..]\n",
    "#     print(classification_report(y_true=y_test, y_pred=yhat_test))  # target_names = target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "charged-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Visualize_confusion_matrix(y, y_pred):\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    cm_df = pd.DataFrame(cm)                 # index=target_names, columns=target_names = target_names\n",
    "    \n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='g', cmap='Blues')\n",
    "    \n",
    "    plt.title('Logistic Regression\\nAccuracy: {0:.3f}'.format(accuracy_score(y, y_pred)))\n",
    "    plt.ylabel('True Values')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "pleasant-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Visualize_data(X1, X2, y, title):\n",
    "    plt.figure(figsize = (6,5))\n",
    "    sns.scatterplot(X1, X2, hue=y, cmap='Sequential')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    return\n",
    "# from mpl_toolkits.mplot3d import Axes3D                       classification: X 3 inputs\n",
    "# fig = plt.figure(figsize=(6,6))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(df['x1'], df['x2'], df['class'], c=df['class'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adjacent-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vẽ đường ROC\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "def ROC_AUC(y, y_prob):\n",
    "    # Calculate roc curves\n",
    "    fpr, tpr, threshold = roc_curve(y, y_prob)\n",
    "    # Calculate scores\n",
    "    model_auc = roc_auc_score(y, y_prob)\n",
    "    \n",
    "    # Calculate the roc curve for the model\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot([0,1], [0,1], linestyle='--', label='No Skill' )\n",
    "    plt.plot(fpr, tpr, marker='.', label='Model - AUC%.3f' % (model_auc))\n",
    "    \n",
    "    plt.title('ROC Curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    plt.show(block=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "friendly-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, precision_recall_curve   # when unbalanced 0 and 1....resample ???\n",
    "def Precision_Recall_AUC(y, y_prob):\n",
    "    precision, recall, threshold = precision_recall_curve(y, y_prob)\n",
    "    model_auc = auc(recall, precision)\n",
    "    \n",
    "    ns = len(y[y==1]) / len(y)\n",
    "    plt.plot([0,1], [ns,ns], linestyle='--', label='No Skill' )\n",
    "    plt.plot(recall, precision, marker='.', label='Model - AUC%.3f' % (model_auc))\n",
    "    \n",
    "    plt.title('Precision_Recall Curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-woman",
   "metadata": {},
   "source": [
    "### Xac dinh nguong toi uu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "legal-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Threshold_ROC(y,y_prob):\n",
    "    # calculate roc curves\n",
    "    fpr, tpr, threshold = roc_curve(y, y_prob)\n",
    "    scores=tpr-fpr\n",
    "    pos= np.argmax(scores)\n",
    "    return threshold[pos],scores[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "illegal-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Threshold_PrecisionRecall(y, y_prob):\n",
    "    precision, recall, threshold = precision_recall_curve(y, y_prob)\n",
    "    score = (2 * precision * recall)/(precision + recall)\n",
    "    pos = np.argmax(score) \n",
    "    \n",
    "    return threshold[pos], score[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "nearby-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def Save_Object(obj,filename):\n",
    "    with open(filename, 'wb') as file:  \n",
    "        pickle.dump(obj, file)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "pending-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(filename, 'rb') as file:\n",
    "#     pickle_model = pickle_load(fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-twist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-workshop",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
